epochs: 200
output_dir: output_dir

model:
  name: Pix2PixModel
  generator:
    name: UnetGenerator
    norm_type: batch
    input_nc: 3
    output_nc: 3
    num_downs: 8 #unet256
    ngf: 64
    use_dropout: False
  discriminator:
    name: NLayerDiscriminator
    ndf: 64
    n_layers: 3
    input_nc: 6
    norm_type: batch
  direction: b2a
  pixel_criterion:
    name: L1Loss
    loss_weight: 100
  gan_criterion:
    name: GANLoss
    gan_mode: vanilla

export_model:
  - {name: 'netG', inputs_num: 1}

dataset:
  train:
    name: PairedDataset
    dataroot: data/cityscapes/train
    num_workers: 4
    batch_size: 1
    preprocess:
      - name: LoadImageFromFile
        key: pair
      - name: SplitPairedImage
        key: pair
        paired_keys: [A, B]
      - name: Transforms
        input_keys: [A, B]
        pipeline:
          - name: Resize
            size: [286, 286]
            interpolation: 'bicubic' #cv2.INTER_CUBIC
            keys: [image, image]
          - name: PairedRandomCrop
            size: [256, 256]
            keys: [image, image]
          - name: PairedRandomHorizontalFlip
            prob: 0.5
            keys: [image, image]
          - name: Transpose
            keys: [image, image]
          - name: Normalize
            mean: [127.5, 127.5, 127.5]
            std: [127.5, 127.5, 127.5]
            keys: [image, image]
  test:
    name: PairedDataset
    dataroot: data/cityscapes/val
    num_workers: 4
    batch_size: 1
    preprocess:
      - name: LoadImageFromFile
        key: pair
      - name: SplitPairedImage
        key: pair
        paired_keys: [A, B]
      - name: Transforms
        input_keys: [A, B]
        pipeline:
          - name: Resize
            size: [256, 256]
            interpolation: 'bicubic' #cv2.INTER_CUBIC
            keys: [image, image]
          - name: Transpose
            keys: [image, image]
          - name: Normalize
            mean: [127.5, 127.5, 127.5]
            std: [127.5, 127.5, 127.5]
            keys: [image, image]

lr_scheduler:
  name: LinearDecay
  learning_rate: 0.0002
  start_epoch: 100
  decay_epochs: 100
  # will get from real dataset
  iters_per_epoch: 1

optimizer:
  optimG:
    name: Adam
    net_names:
      - netG
    beta1: 0.5
  optimD:
    name: Adam
    net_names:
      - netD
    beta1: 0.5

log_config:
  interval: 100
  visiual_interval: 500

snapshot_config:
  interval: 5

validate:
  interval: 29750
  save_img: false
  metrics:
    fid: # metric name, can be arbitrary
        name: FID
        batch_size: 8
